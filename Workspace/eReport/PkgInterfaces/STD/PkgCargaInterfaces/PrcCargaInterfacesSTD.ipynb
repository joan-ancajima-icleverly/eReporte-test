{"cells":[{"cell_type":"code","source":["%run /eReport/PkgGeneral/PrcGeneral"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"81925b8a-9f35-4f79-87b1-519f27880c83"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from datetime import datetime\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom decimal import Decimal\n\nclass PrcCargaInterfaces():\n  \n  def __init__(self, id_solicitud):\n    self.id_solicitud = id_solicitud\n    \n    #Obteniendo parametros\n    parametros = PrcGeneral(id_solicitud = self.id_solicitud).obtenerParametros()\n    self.archivo_entrada = parametros['archivo_entrada']\n    self.tabla_destino = parametros['tabla_destino']\n    self.ruta_origen = '/mnt/ereportinterfaz/inseir/'\n    self.filename = self.ruta_origen + self.archivo_entrada\n        \n    #Fecha de actualizacion\n    fecha_actualizacion = datetime.now()\n    self.fecha_actualizacion = fecha_actualizacion\n    self.fecha_actualizacion_str = fecha_actualizacion.strftime(\"%Y-%m-%d %H:%M:%S\")\n    \n    #Conexion    \n    self.url = \"jdbc:sqlserver://auqui.database.windows.net;database=dbnormativo\"\n    self.usuario = \"administrador\"\n    self.password = \"Auqui$2020\"    \n    \n  #Interface Dias de Atraso\n  def cargarInterfaceDiasAtraso(self): \n          \n    spark = SparkSession.builder.appName(\"Cargar Interface Dias Atraso\").getOrCreate()\n    \n    schema = StructType([StructField('ANIO_PROCESO', IntegerType(), True),\n                         StructField('MES_PROCESO', IntegerType(), True),\n                         StructField('DIA_PROCESO', IntegerType(), True),\n                         StructField('EMPRESA', StringType(), True),\n                         StructField('PRODUCTO_FINANCIERO', IntegerType(), True),\n                         StructField('NUMERO_CUENTA', StringType(), True),\n                         StructField('DIAS_ATRASO', IntegerType(), True),\n                         StructField('TIPO_CREDITO', StringType(), True),\n                         StructField('CODIGO_BLOQUEO', StringType(), True),\n                         StructField('FECHA_VENCIMIENTO', StringType(), True),\n                         StructField('NRO_CUOTAS_VENCIDAS', IntegerType(), True)])\n    \n    df = spark.createDataFrame(spark.sparkContext.textFile(self.filename)\\\n                               .map(lambda x:(int(x[0:4].strip()),\n                                              int(x[4:6].strip()),\n                                              int(x[6:8].strip()),\n                                              x[8:11].strip(),\n                                              int(x[11:13].strip()),\n                                              x[13:33].strip(),\n                                              int(x[33:37].strip()),\n                                              x[37:38].strip(),\n                                              x[38:40].strip(),\n                                              x[40:48].strip(),\n                                              int(x[48:51].strip())\n                                              )), schema)    \n    \n    df = df.withColumn('FECHA_ACTUALIZACION', lit(self.fecha_actualizacion_str))\n    df = df.withColumn('FECHA_ACTUALIZACION', when(col('FECHA_ACTUALIZACION').isNotNull(), col('FECHA_ACTUALIZACION')).otherwise(lit(None)))\n    \n    try:\n      df.write.format(\"com.microsoft.sqlserver.jdbc.spark\")\\\n              .mode(\"overwrite\")\\\n              .option(\"truncate\", \"true\")\\\n              .option(\"url\", self.url)\\\n              .option(\"user\", self.usuario)\\\n              .option(\"password\", self.password)\\\n              .option(\"dbtable\", self.tabla_destino)\\\n              .option(\"tableLock\", \"true\")\\\n              .save()  \n    except:\n        raise;   \n        \n  #Interface Dias de Atraso Detalle\n  def cargarInterfaceDiasAtrasoDetalle(self): \n          \n    spark = SparkSession.builder.appName(\"Cargar Interface Dias Atraso Detalle\").getOrCreate()\n    \n    schema = StructType([StructField('ANIO_PROCESO', IntegerType(), True),\n                         StructField('MES_PROCESO', IntegerType(), True),\n                         StructField('DIA_PROCESO', IntegerType(), True),\n                         StructField('EMPRESA', StringType(), True),\n                         StructField('PRODUCTO_FINANCIERO', IntegerType(), True),\n                         StructField('NUMERO_CUENTA', StringType(), True),\n                         StructField('CONCEPTO_SALDO', IntegerType(), True),\n                         StructField('CLASIFICACION_CONCEPTO', IntegerType(), True),\n                         StructField('MONEDA', StringType(), True),\n                         StructField('IMPORTE_CONCEPTO', DecimalType(15,6), True)])\n    \n    df = spark.createDataFrame(spark.sparkContext.textFile(self.filename)\\\n                               .map(lambda x:(int(x[0:4].strip()),#ANIO_PROCESO\n                                              int(x[4:6].strip()),#MES_PROCESO\n                                              int(x[6:8].strip()),#DIA_PROCESO\n                                              x[8:11].strip(),#EMPRESA\n                                              int(x[11:13].strip()),#PRODUCTO_FINANCIERO\n                                              x[13:33].strip(),#NUMERO_CUENTA\n                                              int(x[33:37].strip()),#CONCEPTO_SALDO\n                                              40,#Confirmar enviar valor en duro\n                                              x[37:40].strip(),#MONEDA\n                                              Decimal(x[40:48].strip())#IMPORTE_CONCEPTO\n                                              )), schema)    \n\n    df = df.withColumn('FECHA_ACTUALIZACION', lit(self.fecha_actualizacion_str))\n    df = df.withColumn('FECHA_ACTUALIZACION', when(col('FECHA_ACTUALIZACION').isNotNull(), col('FECHA_ACTUALIZACION')).otherwise(lit(None)))\n    \n    try:\n      df.write.format(\"com.microsoft.sqlserver.jdbc.spark\")\\\n              .mode(\"overwrite\")\\\n              .option(\"truncate\", \"true\")\\\n              .option(\"url\", self.url)\\\n              .option(\"user\", self.usuario)\\\n              .option(\"password\", self.password)\\\n              .option(\"dbtable\", self.tabla_destino)\\\n              .option(\"tableLock\", \"true\")\\\n              .save()  \n    except:\n        raise;  \n        \n  #Interface Código único Cliente\n  def cargarInterfaceCodigoUnicoCliente(self): \n          \n    spark = SparkSession.builder.appName(\"Cargar Interface Codigo Unico Cliente\").getOrCreate()\n    \n    schema = StructType([StructField('TIPO_MOVIMIENTO', StringType(), True),\n                         StructField('CODIGO_UNICO_CLIENTE', StringType(), True),\n                         StructField('TIPO_DOC_IDENTIDAD', StringType(), True),\n                         StructField('DOC_IDENTIDAD', StringType(), True),\n                         StructField('CIIU', StringType(), True),\n                         StructField('COD_OFICINA', StringType(), True),\n                         StructField('COD_SUBSEDE', StringType(), True),\n                         StructField('TIPO_OFICINA', StringType(), True),\n                         StructField('NUMERO_OFICINA', StringType(), True),\n                         StructField('TIPO_DOC_TRIBUTARIO', StringType(), True),\n                         StructField('DOC_TRIBUTARIO', StringType(), True),\n                         StructField('TIPO_PERSONA', StringType(), True),\n                         StructField('RESIDENCIA', StringType(), True),\n                         StructField('MAGNITUD', StringType(), True),\n                         StructField('ACCIONISTA_EMPRESA', StringType(), True),\n                         StructField('RELACION_LABORAL', StringType(), True),\n                         StructField('PAIS_RESIDENCIA', StringType(), True),\n                         StructField('GENERO', StringType(), True),\n                         StructField('ESTADO_CIVIL', StringType(), True),\n                         StructField('SIGLA', StringType(), True),\n                         StructField('APELLIDO_PATERNO_RAZON_SOCIAL', StringType(), True),\n                         StructField('APELLIDO_MATERNO', StringType(), True),\n                         StructField('APELLIDO_CASADA', StringType(), True),\n                         StructField('PRIMER_NOMBRE', StringType(), True),\n                         StructField('SEGUNDO_NOMBRE', StringType(), True),\n                         StructField('NOMBRES_RESTANTES', StringType(), True),\n                         StructField('DIRECCION', StringType(), True),\n                         StructField('TELEFONO_1', StringType(), True),\n                         StructField('TELEFONO_2', StringType(), True),\n                         StructField('FECHA_NACIMIENTO', StringType(), True),\n                         StructField('OCUPACION', StringType(), True),\n                         StructField('DESCRIPCION_OCUPACION', StringType(), True),\n                         StructField('CODIGO_SECTORISTA', StringType(), True),\n                         StructField('APELLIDO_PATERNO_SECTORISTA', StringType(), True),\n                         StructField('APELLIDO_MATERNO_SECTORISTA', StringType(), True),\n                         StructField('PRIMER_NOMBRE_SECTORISTA', StringType(), True),\n                         StructField('SEGUNDO_NOMBRE_SECTORISTA', StringType(), True),\n                         StructField('CODIGO_AGENCIA_SECTORISTA', StringType(), True),\n                         StructField('NIVEL_RIESGO', StringType(), True),\n                         StructField('FECHA_REVISION', StringType(), True),\n                         StructField('RENTA', DecimalType(12,2), True),\n                         #StructField('RENTA', StringType(), True),\n                         StructField('CODIGO_CLIENTE', StringType(), True),\n                         StructField('TIPO_DOC_COMPLEMENTARIO', StringType(), True),\n                         StructField('DOC_COMPLEMENTARIO', StringType(), True),\n                         StructField('UBIGEO', StringType(), True)])\n    \n    joan = self.filename\n    joan_1 = joan.first\n    joan_filas = joan_1.filter(line => line != joan_1)\n    df = spark.createDataFrame(spark.sparkContext.textFile(joan_filas)\\\n                               .map(lambda x:(x[0:1].strip(),#TIPO_MOVIMIENTO\n                                              x[1:21].strip(),#CODIGO_UNICO_CLIENTE\n                                              x[21:23].strip(),#TIPO_DOC_IDENTIDAD\n                                              x[23:35].strip(),#DOC_IDENTIDAD\n                                              x[35:39].strip(),#CIIU\n                                              x[39:41].strip(),#COD_OFICINA\n                                              x[41:43].strip(),#COD_SUBSEDE\n                                              x[43:44].strip(),#TIPO_OFICINA\n                                              x[44:54].strip(),#NUMERO_OFICINA\n                                              x[54:55].strip(),#TIPO_DOC_TRIBUTARIO\n                                              x[55:75].strip(),#DOC_TRIBUTARIO\n                                              x[75:77].strip(),#TIPO_PERSONA\n                                              x[77:79].strip(),#RESIDENCIA\n                                              x[79:80].strip(),#MAGNITUD\n                                              x[80:82].strip(),#ACCIONISTA_EMPRESA\n                                              x[82:84].strip(),#RELACION_LABORAL\n                                              x[84:88].strip(),#PAIS_RESIDENCIA\n                                              x[88:90].strip(),#GENERO\n                                              x[90:92].strip(),#ESTADO_CIVIL\n                                              x[92:112].strip(),#SIGLA\n                                              x[112:232].strip(),#APELLIDO_PATERNO_RAZON_SOCIAL\n                                              x[232:292].strip(),#APELLIDO_MATERNO\n                                              x[292:352].strip(),#APELLIDO_CASADA\n                                              x[352:412].strip(),#PRIMER_NOMBRE\n                                              x[412:472].strip(),#SEGUNDO_NOMBRE\n                                              x[472:532].strip(),#NOMBRES_RESTANTES\n                                              x[532:782].strip(),#DIRECCION\n                                              x[782:792].strip(),#TELEFONO_1\n                                              x[792:802].strip(),#TELEFONO_2\n                                              x[802:810].strip(),#FECHA_NACIMIENTO\n                                              x[810:812].strip(),#OCUPACION\n                                              x[812:872].strip(),#DESCRIPCION_OCUPACION\n                                              x[872:882].strip(),#CODIGO_SECTORISTA\n                                              x[882:942].strip(),#APELLIDO_PATERNO_SECTORISTA\n                                              x[942:1002].strip(),#APELLIDO_MATERNO_SECTORISTA\n                                              x[1002:1062].strip(),#PRIMER_NOMBRE_SECTORISTA\n                                              x[1062:1122].strip(),#SEGUNDO_NOMBRE_SECTORISTA\n                                              x[1122:1125].strip(),#CODIGO_AGENCIA_SECTORISTA\n                                              x[1125:1126].strip(),#NIVEL_RIESGO\n                                              x[1126:1134].strip(),#FECHA_REVISION\n                                              Decimal(0),#RENTA\n                                              #x[1134:1146].strip(),#RENTA\n                                              x[1146:1149].strip(),#CODIGO_CLIENTE\n                                              x[1149:1151].strip(),#TIPO_DOC_COMPLEMENTARIO\n                                              x[1151:1163].strip(),#DOC_COMPLEMENTARIO\n                                              x[1163:1169].strip()#UBIGEO\n                                              )), schema)\n    \n    df = df.withColumn('FECHA_ACTUALIZACION', lit(self.fecha_actualizacion_str))\n    df = df.withColumn('FECHA_ACTUALIZACION', when(col('FECHA_ACTUALIZACION').isNotNull(), col('FECHA_ACTUALIZACION')).otherwise(lit(None)))\n    #df.select(col('FECHA_REVISION'), col('RENTA'), col('TIPO_DOC_COMPLEMENTARIO')).show(20, False)\n    df.show()\n    df.printSchema()\n    \n    #try:\n    #  df.write.format(\"com.microsoft.sqlserver.jdbc.spark\")\\\n    #          .mode(\"overwrite\")\\\n    #          .option(\"truncate\", \"true\")\\\n    #          .option(\"url\", self.url)\\\n    #          .option(\"user\", self.usuario)\\\n    #          .option(\"password\", self.password)\\\n    #          .option(\"dbtable\", self.tabla_destino)\\\n    #          .option(\"tableLock\", \"true\")\\\n    #          .save()  \n    #except:\n    #    raise;\n        \n#Ejecución de prueba\n#PrcCargaInterfaces(30).cargarInterfaceDiasAtraso()\n#PrcCargaInterfaces(31).cargarInterfaceDiasAtrasoDetalle()\nPrcCargaInterfaces(32).cargarInterfaceCodigoUnicoCliente()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"980cc700-584f-4cec-978d-474f75590a68"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-4163617048385040&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">175</span>\n<span class=\"ansi-red-fg\">    joan_filas = joan_1.filter(line =&gt; line != joan_1)</span>\n                                     ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>","errorSummary":"<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-cyan-fg\">  File </span><span class=\"ansi-green-fg\">&#34;&lt;command-4163617048385040&gt;&#34;</span><span class=\"ansi-cyan-fg\">, line </span><span class=\"ansi-green-fg\">175</span>\n<span class=\"ansi-red-fg\">    joan_filas = joan_1.filter(line =&gt; line != joan_1)</span>\n                                     ^\n<span class=\"ansi-red-fg\">SyntaxError</span><span class=\"ansi-red-fg\">:</span> invalid syntax\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PrcCargaInterfacesSTD","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2534754005637541}},"nbformat":4,"nbformat_minor":0}